---
layout: post
title: Flink安装指南
date: 2020-07-15
categories: bigdata flink
tags: flink 安装指南
permalink: install_flink
published: true
---

jdk 、 scala 和 haodop 在之前的文章 [Hadoop安装指南](install_hadoop) 、 [Spark安装指南](install_spark) 详细介绍过安装方法。现在介绍安装 flink ，同样是在单个节点上安装用来学习。

## 安装环境

- ubuntu-20.04.3 LTS

- jdk-1.8.0_321

- scala-2.12.15

- hadoop-2.10.1

- spark-3.1.2

- flink-1.13.5

- apache-maven-3.8.4

## 安装 flink

在 [Flink 官网](https://flink.apache.org) 下载所需要版本的 flink 安装包，解压到 `/usr/local` 文件夹中。在 `~/.bashrc` 中设置环境变量。

```bash  
# set flink home.
export FLINK_HOME=/usr/local/flink
export PATH=$FLINK_HOME/bin:$PATH
```

## 编译安装 flink

[Building Flink from Source](https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/flinkdev/building/)，因为需要阅读 flink 的源码，所以需要编译一遍 flink 的源码才方便调试和阅读。

### 克隆 flink 代码

```bash
git clone https://github.com/apache/flink.git
```

### 编译 flink

因为我们使用的 scala 版本为 2.12 ，而编译时默认 scala 版本为 2.11 ，所以要指定一下 scala 的版本。

```bash
# -T 4                      : 允许多线程编译，推荐 maven-3.3 及以上版本
# -Dmaven.compile.fork=true : 支持多处理器或者处理器核数参数，加快构建速度，推荐 maven3.3 及以上版本
mvn clean install -DskipTests -Dscala-2.12 -T 4 -Dmaven.compile.fork=true
```

## 修改 flink 配置文件

### masters

```bash
localhost:8081
```

### workers

```bash
localhost
```

## 启动 flink

```bash
$FLINK_HOME/bin/start-cluster.sh
```

- 使用 `jps` 命令查看进程是否启动

  如果 flink 成功启动则会有以下 2 个进程。

  ```conf
  TaskManagerRunner
  StandaloneSessionClusterEntrypoint
  ```

- Web UI 查看集群状态

  [`http://localhost:8081/`](http://localhost:8081/)
